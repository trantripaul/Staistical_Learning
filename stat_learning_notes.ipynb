{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Intro To Statistical Learning"
      ],
      "metadata": {
        "id": "mJqYzmCCjsEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITUfziYG3TAu",
        "outputId": "2e550671-1bb5-4b91-acc6-9d3db02bab8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color = \"blue\">**2.1 What is Statistical Learning</font>**\n",
        "\n",
        "* Demonstration:\n",
        "  - Look at <font color = \"brown\">Advertising</font> data set that consists of <font color = \"brown\">sales</font> in 200 different markets\n",
        "  - Look at advertising budget for <font color = \"brown\">TV, radio, newspaper</font>.\n",
        "  - Can't directly increase sales ‚Üí look at correlation between advertising and sale\n",
        "  - want to develop accurate model used to predict sales based on media budgets\n",
        "  - input - ad budgets\n",
        "    - aka predictors, independent variables, features\n",
        "  - output - <font color = \"brown\">sales</font>\n",
        "    - aka *response* or *dependent variable*\n"
      ],
      "metadata": {
        "id": "Y0NvMSpPoZdG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notation:\n",
        "\n",
        "\n",
        "*   Y - response\n",
        "*   X - features, predictors, input\n",
        "*   n - # of distinct data points\n",
        "\n",
        "  \\begin{align}\n",
        "    X = \\begin{pmatrix}\n",
        "          x_1 \\\\\n",
        "          x_2 \\\\\n",
        "          x_3\n",
        "        \\end{pmatrix}  \n",
        "  \\end{align}\n",
        "\n",
        "  Write model as:\n",
        "\n",
        "  \\begin{align}\n",
        "    Y = f(x) + œµ\n",
        "  \\end{align}\n",
        "\n",
        "  where œµ is error/discrepancy"
      ],
      "metadata": {
        "id": "1K3I0xXujzLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=\"blue\">What is f(x) good for?</font>**\n",
        "\n",
        "*    make predictions of y\n",
        "  - $\\hat Y = \\hat f(X)$\n",
        "      - accuracy of $\\hat Y$ depends on the *reducible error* and *irreducible error*\n",
        "\n",
        "\\begin{align}\n",
        "  E(Y-\\hat Y)^2 &= E[f(X) + \\epsilon - \\hat f(X)]^2 \\\\\n",
        "  &= [f(X) - \\hat f(X)]^2 + Var(œµ) )\n",
        "\\end{align}  \n",
        "\n",
        "*    understand what components of $X=(X_1,X_2,...X_p)$ are important to explaining Y\n",
        "\n",
        "* Inference\n",
        "  - Which predictors are associated with response?\n",
        "  - What is the relationship between the response with each predictor\n",
        "  - Can the relationship between Y and each predictor be adequately summarized using linear equation, or is the relationship more complicated?"
      ],
      "metadata": {
        "id": "UFgZCE0xlHZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=\"blue\">Is there an ideal f(x)</font>**\n",
        "*    The ideal formula $f(x) = E(Y|X = x)$ is called the <font color = \"green\">regression formula</font>"
      ],
      "metadata": {
        "id": "S6hjERwImoV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=\"red\">Dimenstionality and Structured models</font>**\n",
        "\n",
        "* Nearest Neighbor averaging good for small $p$\n",
        "  - bad for large p due to <font color = \"green\">curse of dimensionality </font>\n",
        "  - nearest neighbors are further away in higher dimensions\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eQjDyZzxrP33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=\"blue\">Parametric and structured models</font>**\n",
        "* work around to fix nearest neighbor problem is a <font color=\"green\"> linear  model</font>(this is an example of a parametric model)\n",
        "\n",
        "\\begin{align}\n",
        "  f_{L}(X) = Œ≤_0 + Œ≤_1X_1 + Œ≤_2X_2 + ... + Œ≤_pX_p\n",
        "\\end{align}\n",
        "\n",
        "‚Ü™ specified in terms of $p+1$ parameters $Œ≤_0, Œ≤_1, ... ,Œ≤_p$\n",
        "*    estimate parameters by fitting model to training data\n",
        "  \n",
        "  ‚Ü™ typically never correct ‚Üí linear model serves as an approximation to the unknown true function $f(X)$"
      ],
      "metadata": {
        "id": "160WcDDfcNBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "****<font color=\"blue\">Trade offs</font>****\n",
        "*    Prediction vs interpretability\n",
        "*    Good fit vs underfit or overfit\n",
        "*    Parsimary vs blackbox\n",
        "\n",
        "* Why choose a more restrictive method vs a more refllexive one?\n",
        "  - restricitve models are more interpretable"
      ],
      "metadata": {
        "id": "mZi2k-jefLZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color = \"red\">Model Selection and Bias Variance Tradeoff</font>**"
      ],
      "metadata": {
        "id": "n2K8mZTsrW12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color = blue>Assessing Model Accuracy</font>**\n",
        "\n",
        "*    suppose we fit a model $\\widehat f(x)$  to some training data $Tr = \\{X_i, Y_i\\}^{N}_{1}$\n",
        "\n",
        "    ‚Ü™ see how well it performs by computing MSE\n",
        "\n",
        "\\begin{align}\n",
        "  MSE_{Tr} = Ave_{i œµ Tr}[y_i-\\hat f(x_i)]^2\n",
        "\\end{align}\n",
        "\n",
        "*    might be biased toward more over fit models ‚Üí do the same for test data(<font color = \"green\">fresh data</font>)\n",
        "\n",
        "\\begin{align}\n",
        "  MSE_{Te} = Ave_{i œµ Te}[y_i-\\hat f(x_i)]^2\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "182zA_CDiUyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color = \"blue\">Bias-Variance Trade-Off</font>**\n",
        "*    Suppose we fit a model $\\hat f(x)$ to some training data $Tr$\n",
        "  -   Let $(x_0, y_0)$ be a test observation drawn from populaion\n",
        "      -   if true model is $Y = f(x)+ œµ$ with $f(x) = E(Y|X=x)$ then:\n",
        "\n",
        "      \\begin{align}\n",
        "        E(y_0 - \\hat f(x_0))^2 = Var(\\hat f(x_0)) + [Bias(\\hat f(x_0))]^2 + Var(œµ)\n",
        "      \\end{align}\n",
        "*    Note: $Bias(\\hat F(x_0)) = E[\\hat f(x_0)] - f(x_0)$\n",
        "  -    typically as $\\hat f$ increases ‚Üí variance ‚áë, bias ‚Üì\n",
        "\n",
        "  ‚Ü™ choose flexibility on test error ‚Üí <font color = \"green\"> bias variance tradeoff</font>"
      ],
      "metadata": {
        "id": "IgOR9ELbc2WY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=\"red\">Classification</font>**"
      ],
      "metadata": {
        "id": "mEUXToeFfayx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=\"blue\"> Classification Problems</font>**\n",
        "  \n",
        "*     spam or ham\n",
        "    \n",
        "  - Y in this case is <font color = \"green\">qualitative</font>\n",
        "  - ùê∂ = (spam, ham) ‚Üí digit class ùê∂ = (0,1,2, ... , 9)\n",
        "\n",
        "    ‚Ü™ build classifier ùê∂(x) that assignes a class label to a future observation of X\n",
        "\n",
        "*    measure performace of $\\hat C(x)$ by using misclassification error rate\n",
        "\n",
        "\\begin{align}\n",
        "  Err_{Te} = Ave_{i œµTe}I[y_i \\neq \\widehat C(x_i)]\n",
        "\\end{align}\n",
        "\n",
        "**Some notes on K nearest neighbors**\n",
        "*   Too many dimensions will lead to underfitting and to little dimensions will lead to over fitting"
      ],
      "metadata": {
        "id": "JLuXB94UfZY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "o7eC1R9Cu337"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=\"blue\">Linear Regression Using a single predictor X</font>**\n",
        "\n",
        "-    Assume a model\n",
        "\n",
        "\\begin{align}\n",
        "  Y = Œ≤_0 + \\beta_1X + œµ\n",
        "\\end{align}\n",
        "\n",
        "  where $Œ≤_1$ and $Œ≤_0$ are 2 unknown constants(represent <font color = green>slope</font> and <font color = green>intercept</font>)\n",
        "\n",
        "  ‚Ü™ aka <font color = green>coeffecients</font> or <font color = green>parameters</font>\n",
        "\n",
        "-    Given som estimates $\\hat Œ≤_0$ and $\\hat Œ≤_1$ ‚Üí predict future sales using\n",
        "\n",
        "\\begin{align}\n",
        "  \\hat y = \\hat Œ≤_0 + Œ≤_1x\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "LGnrJXAuvBRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font color=\"blue\">Estimation of the parameters by least squares</font>**\n",
        "\n",
        "-    let $\\hat y_i = \\hat Œ≤_0 + \\hat Œ≤_ix_i$ ‚Üí based on its $ith$ value of $x$\n",
        "‚Ü™ then $e_i = y_i - \\hat y_i$ represents the <font color = \"green\">residual</font>\n",
        "-    <font color = \"green\">residual sum of squares</font>(RSS)\n",
        "\n",
        "\\begin{align}\n",
        "  RSS  &= e^2_1 + e^2_2 + ... + e^2_n \\\\\n",
        "  &=(y_1 - \\hat Œ≤_0 - \\hat Œ≤_1x_1)^2 + (y_2- \\hat Œ≤_0 - \\hat Œ≤x_2)^2 + ... + (y_n- \\hat Œ≤_0 - \\hat Œ≤x_n)^2\n",
        "\\end{align}\n",
        "\n",
        "**<font color=\"blue\">Assessing the accuracy of coefficient estimates</font>**\n",
        "-   \n"
      ],
      "metadata": {
        "id": "tlwBmLA_gpfH"
      }
    }
  ]
}